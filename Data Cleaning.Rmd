---
title: "Data_Cleaning"
output: pdf_document
---

```{r, include = FALSE}
library(tidyverse)
library(sjlabelled)  # for remove_all_labels()


# import
load('ICPSR_20520/DS0001/20520-0001-Data.rda')

# get features and response
cils <- as_tibble(da20520.0001) %>%
  filter(!is.na(V421)) %>%
  remove_all_labels()
```

```{r}
head(da20520.0001[1:14])
```

Our original dataset, "da20520.0001," is vast, consisting of 5262 observations with 665 variables. The chart above shows the first 14 columns of our dataset. Since we wanted to use the LASSO method to select the model, we had to do lots of data cleaning. Here are some steps that we used for the data cleaning. 

(1) Our goal here is to select the best model with the most predictive power. Our response variable is income, so we concluded that we don't want rows with NA in `V421`, which represents the income of the individuals. We deleted all of such rows. 

(2) For our prediction, we checked if our response variable, `V421`, is approximately normal. As you see on the left histogram, our original `V421` is heavily skewed, so we had performed a log transformation to make it approximately normal (See the right histogram).


```{r, fig.width=3, fig.height = 3, echo = FALSE}
ggplot(cils, aes(x = V421)) + 
  geom_histogram(na.rm = TRUE, binwidth = 500,
                 fill="#69b3a2", color="#e9ecef", alpha=0.9) +
  xlab("Income") +
  ylab("Frequency")

ggplot(cils, aes(x = log(V421))) + 
  geom_histogram(na.rm = TRUE,binwidth = 0.4,
                 fill="#69b3a2", color="#e9ecef", alpha=0.9) +
  xlab("Income") +
  ylab("Frequency")
```

```{r, echo = FALSE}
income <- cils %>%
  pull(V421) %>%
  log()

# drop 2005 variables
cils <- cils %>%
  select(!matches('V4[[:alnum:]]{2,}'))

# deal with numeric variables
numeric <- cils %>%
  select(where(is.double)) %>%
  select(!CASEID)

numeric <- numeric %>%
  select(where(~ sum(is.na(.x)) / length(.x) < 0.5)) %>%                        # select variables less than 50% NA
  mutate(across(.cols = everything(), is.na, .names = '{.col}_NA')) %>%         # add dummy NA columns
  mutate(across(.cols = ends_with('_NA'), as.double)) %>%                       # turn dummy NA columns to double
  mutate(across(.cols = !ends_with('_NA'), ~
                  if_else(is.na(.x), mean(.x, na.rm = TRUE), .x))) %>%          # mean imputation
  as.matrix()

# deal with categorical variables
categorical <- cils %>%
  select(where(is.factor))

many_levels <- c('V32', 'V37', 'V233', 'V238', 'V263', 'V62', 'V64', 'V264')    # occupations

categorical <- categorical %>%
  select(where(~ sum(is.na(.x)) / length(.x) < 0.5)) %>%
  select(where(~ nlevels(.x) <= 25)) %>%
#  select(!all_of(many_levels)) %>%                                              # drop variables with too many levels
  mutate(across(.cols = everything(), addNA))                                   # make NA a level
categorical <- model.matrix(~ ., data = categorical)[ ,-1]                      # create design matrix, excluding intercept

```

(3) This data frame consists of results of all responses from a total of 4 different surveys. In other words, this data frame recorded the response of individuals who took the four different surveys at different stages of their lifetime. Since using all four surveys will create dependency in terms of time series, we decided to use only the responses collected when individuals were attending high school.

One of the big issues we faced for using LASSO for our variable selection was that we had many NA values across the data frame, and LASSO couldn't handle the NAs. To tackle this issue, we used many assumptions to either replace or delete the NAs. 

(1) We assumed that the column with more than 50% of NAs is not informative, so those columns were removed. 

(2) Second, for the categorical variables, we assumed that the columns with more than 25 categories are causing a problem with the predictive power of LASSO, so we removed all of such variables. For example, variables `V32`, `V37`, `V233`, `V238`, `V263`, `V62`, `V64`, `V264` have more than 100 categories (occupations), and they have only 2~3 data points for many of them. We assumed that this lack of data points in each category is causing problems in the predictive power of the LASSO. We wanted to ensure that each category had at least 100 data points for each column, so we divided our number of observations (around 2500) by 100, equal to 25. We know that this calculation is not great, but we used this because we needed a rule of thumb for the numbers of categories in each column. 

(3) Since the LASSO couldn't handle the NAs, we used the imputation to replace the NA values. For the numerical variable, we used the mean of each variable to replace the NA. Here we did not want to simply replace the NA because it would raise a problem of non-response bias, so we included the dummy column with 1 and 0 so that we can still keep track of all NA values for each variable. For categorical variables, we just simply made NA as a level. 
